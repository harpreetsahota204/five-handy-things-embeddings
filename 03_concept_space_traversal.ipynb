{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Space Traversal\n",
    "\n",
    "Concept space traversal is the exploration of high-dimensional embedding spaces where data points represent semantic relationships between concepts. It enables navigation and manipulation of semantic relationships captured by embeddings, providing a powerful tool for exploring abstract concept spaces in various AI and machine learning applications.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **Embedding Space**: \n",
    "   - High-dimensional vector space\n",
    "   - Similar concepts positioned closer together\n",
    "\n",
    "2. **Similarity Measures**:\n",
    "   - Typically cosine similarity or Euclidean distance\n",
    "   - Closer points indicate higher semantic similarity\n",
    "\n",
    "3. **Traversal Methods**:\n",
    "   a. Linear Interpolation:\n",
    "      - Create intermediate points between concepts\n",
    "      - Use weighted averages of vector representations\n",
    "\n",
    "   b. Vector Arithmetic:\n",
    "      - Perform operations (e.g., addition, subtraction) on vectors\n",
    "      - Explore relationships and analogies\n",
    "\n",
    "   c. Nearest Neighbor Search:\n",
    "      - Find closest points to a given vector\n",
    "      - Discover related concepts\n",
    "\n",
    "## Applications\n",
    "\n",
    "- Concept generation\n",
    "- Similarity search\n",
    "- Analogy discovery\n",
    "- Semantic relationship exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.utils.huggingface as fouh\n",
    "\n",
    "color_swap = fouh.load_from_hub(\n",
    "    \"Voxel51/ColorSwap\",\n",
    "    name=\"colorswap_full\",\n",
    "    max_samples=551,\n",
    "    persistent=True,\n",
    "    overwrite=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Concept Traversal Plugin for FiftyOne allows users to navigate the space of concepts in their dataset using both text and images. \n",
    "\n",
    "Key points:\n",
    "\n",
    "- You select a starting image from their dataset, then iteratively add text concepts with relative strengths to move around the multimodal embedding space.\n",
    "\n",
    "- Behind the scenes, it generates embedding vectors for the text prompts, combines them with the starting image vector, and performs a similarity search on the dataset.\n",
    "\n",
    "- Creating the plugin required generating a multimodal similarity index (e.g. using a CLIP model) on the dataset first.\n",
    "\n",
    "To use the plugin, a similarity index that supports prompts (i.e., embeds both text and images) must be present on the dataset. \n",
    "\n",
    "This can be created using the `fiftyone.brain` module, specifically the `compute_similarity` function, which takes the dataset, a `brain_key`, the `model_name` (e.g., `clip-vit-base32-torch`), and the `metric` (e.g., `cosine`) as arguments.\n",
    "\n",
    "The plugin can be installed by running the command `fiftyone plugins download https://github.com/jacobmarks/concept-interpolation`.\n",
    "\n",
    "The plugin provides two main operators:\n",
    "\n",
    "1. `open_interpolation_panel`: Opens the interpolation panel when clicked, but is only activated when the dataset has a similarity index.\n",
    "\n",
    "2. `interpolator`: Runs the actual interpolation between the two text prompts.\n",
    "\n",
    "In summary, this FiftyOne plugin enables users to explore the latent space between two text concepts by interpolating between their embeddings and visualizing the results, providing an interactive way to understand the relationships between different text prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = foz.load_zoo_model(\n",
    "    name=\"clip-vit-base32-torch\",\n",
    "    install_requirements=True,\n",
    ")\n",
    "\n",
    "color_swap.compute_embeddings(\n",
    "    model=clip_model,\n",
    "    embeddings_field=\"clip_embeddings\",\n",
    "    progress=True,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "sim_index = fob.compute_similarity(\n",
    "    color_swap,\n",
    "    brain_key=\"concept_embeddings\",\n",
    "    embeddings=\"clip_embeddings\",\n",
    "    model=\"clip-vit-base32-torch\",\n",
    "    metric=\"cosine\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fob.compute_visualization(\n",
    "    color_swap,\n",
    "    embeddings=\"clip_embeddings\",\n",
    "    method=\"umap\",\n",
    "    brain_key = \"umap_2d_clip\",\n",
    "    num_dims=2,\n",
    "    progress=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(color_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
